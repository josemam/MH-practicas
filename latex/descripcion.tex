\section{Descripción del problema}

El aprendizaje automático supervisado contempla, entre otros problemas, la obtención de métodos de clasificación, los cuales tratan de asignar clases a datos a partir de una muestra de datos clasificados según un criterio a priori desconocido por la máquina. Uno de los algoritmos de clasificación más conocidos es la clasificación $k$-NN, en la que a cada dato se le asigna la clase más común de sus $k$ vecinos más \textit{cercanos}. Para ello se define una función que computa la distancia entre dos datos, que se representan como una tupla de valores numéricos o categóricos; se evalúa la distancia entre el dato a clasificar y todos los elementos de una muestra de entrenamiento y se asigna la categoría más frecuente en los $k$ datos de la muestra que están a menor distancia del dato. Una versión general del problema propuesto consistiría en obtener una función distancia que, al ser utilizada, permita elaborar un clasificador óptimo en cierto sentido. \\

Para las prácticas de esta asignatura se aplicarán las siguientes restricciones al problema general:
\begin{itemize}
  \item Se considera la clasificación $1$-NN, donde simplemente se asigna a cada dato la clase del dato a menor distancia de este (llamado su \textit{vecino más cercano}) en la muestra de entrenamiento.
  \item Se utilizará como espacio de posibles funciones distancia aquellas de la forma $\sqrt{\sum_i w_i (x_i - d_i)^2}$ donde $x_i$ y $d_i$ son la componente $i$-ésima de las tuplas que representan, respectivamente, un dato de la muestra de entrenamiento $\normalfont \textbf x$ y un dato a clasificar $\normalfont \textbf d$, y $w_i$ es el elemento $i$-ésimo de un conjunto de \textbf{pesos} expresados como números reales nulos o en el intervalo $[0.2,\ 1]$. No será necesario computar la raíz cuadrada debido a que esta operación es biyectiva y monótona para números reales no negativos ($a = b \Leftrightarrow \sqrt a = \sqrt b$ y $a < b \Leftrightarrow \sqrt a < \sqrt b$) y por ello no afecta al cálculo del vecino más cercano. Por esta restricción, el problema se reduce a encontrar (o aprender) un conjunto de pesos $\normalfont \textbf w$ que conlleve un clasificador óptimo.
  \item Se evaluará cada clasificador según su capacidad para etiquetar elementos correctamente, el número de características que no considere y el tiempo de ejecución del algoritmo que se había utilizado para obtener el clasificador. Por la condición anterior, esto equivale a que se evalúe cada conjunto de pesos por la tasa de clasificaciones correctas de su clasificador, su número de pesos nulos y el tiempo necesario para obtener tales pesos.
\end{itemize}

El objetivo de todas las prácticas de esta asignatura será desarrollar, implementar y comparar algoritmos que, a partir de unos datos, tratan de obtener pesos óptimos para las características de dichos datos según el criterio de evaluación especificado.

